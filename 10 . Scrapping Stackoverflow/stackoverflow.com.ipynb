{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cf7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTML,HTMLSession\n",
    "import pandas as pd \n",
    "\n",
    "import time \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55252b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Flow :\n",
    "#     1)scarpe_and_save_csv()\n",
    "#     2)scarpe_tag()\n",
    "#     3)extract_data_from_url()\n",
    "#     4)parse_tagged_page()\n",
    "#     5)clean_scarped_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca75fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(),\"OUTPUT_CSVs\"),exist_ok=True)\n",
    "output_dir = os.path.join(os.getcwd(),\"OUTPUT_CSVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236f678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data further\n",
    "def clean_scarped_data(text,keyname=None):\n",
    "    if keyname == \"votes\":\n",
    "        return text.replace(\"\\nvotes\",\"\") \n",
    "    if keyname == \"tags\":\n",
    "        return list(text.split(\" \"))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ea09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to grab the necessary class and scrap those vital data and returned in the form of a lsit \n",
    "def parse_tagged_page(html):\n",
    "    list_of_question_summary = html.find(\".question-summary\")\n",
    "    key_names = [\"question\",\"votes\",\"tags\"]\n",
    "    classes_needed = ['.question-hyperlink','.vote',\".tags\"]\n",
    "    datas = []\n",
    "    for q_el in list_of_question_summary:\n",
    "        question_data = {}\n",
    "        for i,lookup_class in enumerate(classes_needed):\n",
    "            sub_el = q_el.find(lookup_class,first=True)\n",
    "            keyname = key_names[i]\n",
    "            question_data[keyname] = clean_scarped_data(sub_el.text,keyname=keyname)\n",
    "        datas.append(question_data)\n",
    "    return datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed07204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a get request and passes the html text for parsing \n",
    "def extract_data_from_url(url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code not in range(200,299):\n",
    "        return []\n",
    "    html_str = r.text\n",
    "    html = HTML(html=html_str)\n",
    "    datas = parse_tagged_page(html)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7d54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define the final endpoints with all the queries passed\n",
    "def scarpe_tag(tag=\"python\",query_filter=\"votes\",max_pages=10,pagesize=10):\n",
    "    base_url = \"https://stackoverflow.com/questions/tagged/\"\n",
    "    datas = []\n",
    "    for p in range(max_pages):\n",
    "        page_num= p+1\n",
    "        final_endpoint = f\"{base_url}{tag}?tab={query_filter}&page={page_num}&pagesize={pagesize}\"\n",
    "        datas += extract_data_from_url(final_endpoint)\n",
    "        time.sleep(0.5)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c6c2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes list of tags and scrapes those tags \n",
    "def scarpe_and_save_csv(tags_list=[]):\n",
    "    if len(tags_list) == 0:\n",
    "        raise Exception(\"tags_list cannot be empty\")\n",
    "    for tag in tags_list:\n",
    "            datas = scarpe_tag(tag)\n",
    "            df = pd.DataFrame(datas)\n",
    "            df.head(n=10)\n",
    "            df.to_csv(os.path.join(output_dir,f\"{tag}.csv\"),index=False)\n",
    "            print(f\"{tag}.csv saved\")\n",
    "            time.sleep(1)\n",
    "    print(\"Scrapping Done ! Peace \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aff6f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript.csv saved\n",
      "python.csv saved\n",
      "java.csv saved\n"
     ]
    }
   ],
   "source": [
    "scarpe_and_save_csv(['javascript','python','java'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
